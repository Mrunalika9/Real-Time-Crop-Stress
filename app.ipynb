{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqFPNodq8F3L2KbAwp0OBv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mrunalika9/Real-Time-Crop-Stress/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAkrJjFjYH49",
        "outputId": "e4b6b487-e5e6-4202-ebe8-5b524e26f81f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-08 13:36:29.238 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.239 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.379 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-04-08 13:36:29.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.381 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.385 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.393 Session state does not function when running a script without `streamlit run`\n",
            "2025-04-08 13:36:29.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-08 13:36:29.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "from geopy.geocoders import Nominatim\n",
        "from datetime import datetime, timedelta\n",
        "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "# ğŸŒ¾ Page Setup\n",
        "st.set_page_config(page_title=\"Crop Stress Detector\", layout=\"centered\")\n",
        "st.title(\"ğŸŒ¾ Real-Time Crop Stress Detection App\")\n",
        "st.write(\"Predict crop stress using real-time weather data and simulated NDVI values.\")\n",
        "\n",
        "# ğŸ“ Get location input\n",
        "place = st.text_input(\"ğŸ“ Enter a location name (e.g., Punjab, India):\")\n",
        "\n",
        "# Function to fetch coordinates\n",
        "def get_coordinates(location_name):\n",
        "    try:\n",
        "        geolocator = Nominatim(user_agent=\"chaitu_crop_stress_detector\")\n",
        "        location = geolocator.geocode(location_name, timeout=10)\n",
        "        if location:\n",
        "            return location.latitude, location.longitude\n",
        "        else:\n",
        "            return None, None\n",
        "    except (GeocoderTimedOut, GeocoderServiceError) as e:\n",
        "        st.error(f\"Geocoding error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "if place:\n",
        "    LAT, LON = get_coordinates(place)\n",
        "\n",
        "    if LAT and LON:\n",
        "        st.success(f\"âœ… Found coordinates: Latitude = {LAT}, Longitude = {LON}\")\n",
        "\n",
        "        # ğŸ—“ Set date range (last 15 days)\n",
        "        end_date = datetime.today()\n",
        "        start_date = end_date - timedelta(days=15)\n",
        "        START_DATE = start_date.strftime('%Y%m%d')\n",
        "        END_DATE = end_date.strftime('%Y%m%d')\n",
        "\n",
        "        st.write(f\"ğŸ“… Fetching weather data from **{START_DATE}** to **{END_DATE}**\")\n",
        "\n",
        "        # ğŸŒ¤ Fetch weather data\n",
        "        NASA_API = (\n",
        "            f\"https://power.larc.nasa.gov/api/temporal/daily/point?\"\n",
        "            f\"parameters=T2M,RH2M&community=AG&longitude={LON}\"\n",
        "            f\"&latitude={LAT}&start={START_DATE}&end={END_DATE}&format=JSON\"\n",
        "        )\n",
        "\n",
        "        response = requests.get(NASA_API)\n",
        "        data = response.json()\n",
        "\n",
        "        if 'properties' not in data or 'parameter' not in data['properties']:\n",
        "            st.error(\"âŒ Invalid API response. Check the location or date range.\")\n",
        "        else:\n",
        "            daily_data = data['properties']['parameter']\n",
        "            dates = list(daily_data['T2M'].keys())\n",
        "            ndvi_values = np.random.uniform(0.2, 0.9, size=len(dates))  # Simulated NDVI\n",
        "\n",
        "            records = []\n",
        "            for i, date in enumerate(dates):\n",
        "                temp = daily_data['T2M'][date]\n",
        "                humidity = daily_data['RH2M'][date]\n",
        "                ndvi = ndvi_values[i]\n",
        "                rain = np.random.uniform(0, 15)\n",
        "\n",
        "                if ndvi < 0.3 and temp > 35:\n",
        "                    stress = 'High'\n",
        "                elif ndvi > 0.6:\n",
        "                    stress = 'Low'\n",
        "                else:\n",
        "                    stress = 'Moderate'\n",
        "\n",
        "                records.append({\n",
        "                    \"date\": date,\n",
        "                    \"temperature\": temp,\n",
        "                    \"rainfall\": rain,\n",
        "                    \"humidity\": humidity,\n",
        "                    \"ndvi\": ndvi,\n",
        "                    \"stress_level\": stress\n",
        "                })\n",
        "\n",
        "            df = pd.DataFrame(records)\n",
        "\n",
        "            st.subheader(\"ğŸ§¾ Sample Weather + NDVI Data\")\n",
        "            st.dataframe(df)\n",
        "\n",
        "            # ğŸ§  ML Processing\n",
        "            X = df[[\"temperature\", \"rainfall\", \"humidity\", \"ndvi\"]]\n",
        "            y = df[\"stress_level\"]\n",
        "\n",
        "            label_encoder = LabelEncoder()\n",
        "            y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "            # Safe split even with few samples\n",
        "            try:\n",
        "                X_train, X_test, y_train, y_test = train_test_split(\n",
        "                    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        "                )\n",
        "            except ValueError:\n",
        "                X_train, X_test, y_train, y_test = train_test_split(\n",
        "                    X, y_encoded, test_size=0.2, random_state=42\n",
        "                )\n",
        "                st.warning(\"âš ï¸ Not enough samples in some classes for stratify â€” using random split.\")\n",
        "\n",
        "            model = RandomForestClassifier(random_state=42)\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "\n",
        "            labels_present = unique_labels(y_test, predictions)\n",
        "            target_names_present = label_encoder.inverse_transform(labels_present)\n",
        "\n",
        "            # ğŸ§¾ Show classification report\n",
        "            report = classification_report(\n",
        "                y_test, predictions,\n",
        "                labels=labels_present,\n",
        "                target_names=target_names_present,\n",
        "                zero_division=0\n",
        "            )\n",
        "            st.subheader(\"ğŸ“‹ Classification Report\")\n",
        "            st.text(report)\n",
        "\n",
        "            # ğŸ”® Predict today's stress level\n",
        "            latest_input = df.iloc[[-1]][[\"temperature\", \"rainfall\", \"humidity\", \"ndvi\"]]\n",
        "            predicted_encoded = model.predict(latest_input)\n",
        "            predicted_stress = label_encoder.inverse_transform(predicted_encoded)\n",
        "\n",
        "            st.subheader(f\"ğŸŒ¿ Predicted Stress Level for {df.iloc[-1]['date']}\")\n",
        "            st.success(f\"**{predicted_stress[0]}**\")\n",
        "\n",
        "            # ğŸ“ˆ NDVI chart\n",
        "            st.subheader(\"ğŸ“Š NDVI Over Time\")\n",
        "            fig, ax = plt.subplots(figsize=(8, 5))\n",
        "            ax.bar(df['date'], df['ndvi'], color='green')\n",
        "            ax.set_title('NDVI Over Time')\n",
        "            ax.set_ylabel('NDVI')\n",
        "            ax.set_xlabel('Date')\n",
        "            plt.xticks(rotation=45)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "    else:\n",
        "        st.error(\"âŒ Could not find the location.\")\n"
      ]
    }
  ]
}